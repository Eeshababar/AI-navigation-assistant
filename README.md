# ðŸ¦¾ AI Navigation Assistant

An **AI-powered mobility assistant** for visually impaired individuals.  
It combines **computer vision**, **generative AI reasoning**, and **agentic workflows** to detect obstacles, estimate distances, generate adaptive guidance, and alert caregivers when necessary.  

---

## ðŸš€ Features
- ðŸ” **Obstacle Detection** â€“ YOLOv12 for robust real-time object recognition  
- ðŸ“ **Distance Estimation** â€“ MiDaS for monocular depth sensing  
- ðŸ¤– **Contextual Reasoning** â€“ GPT-5 for adaptive navigation and situational awareness  
- ðŸŽ¥ **Video Inference** â€“ Roboflow integration for live object/video stream processing  
- ðŸ—£ **Voice Feedback** â€“ gTTS for natural audio navigation cues  
- ðŸ“§ **Caregiver Alerts** â€“ Automated email notifications via **LangGraph agentic workflows**  
- ðŸ§­ **Adaptive Navigation** â€“ Agents plan responses (alert, reroute, stop, proceed)  

---

## ðŸ–¼ï¸ System Architecture
```mermaid
graph TD
    A[Camera Input] --> B[YOLOv12 - Obstacle Detection]
    B --> C[MiDaS - Depth Estimation]
    C --> D[GPT-5 - Inference & Decisions]
    D --> E[gTTS - Voice Output]
    D --> F[Roboflow - Video Inference]
    D --> G[LangGraph Agent - Caregiver Email Alerts]
